"""
SCP Generation Demo — See what Gemini 3 Pro produced from an 815-token contract.

Run:  python demo.py
"""
import inspect
import textwrap

# Import the AI-generated module
from transcriber import (
    load_model, transcribe_file, batch_transcribe, transcribe_segment,
    Transcript, TranscriptSegment,
)


def section(title):
    print(f"\n─── {title} ───\n")


def main():
    print("=" * 70)
    print("◬  Transcriber — AI-Generated Module Demo")
    print("   Generated by Gemini 3 Pro from an ~815 token SCP contract")
    print("   The AI never saw the TurboScribe codebase (~110,000 tokens)")
    print("=" * 70)

    # ── Show the 4 public functions and their contracts ──
    section("Glyph Contracts (4 methods)")

    apis = [
        ("◬ Origin",    load_model,          "Singleton model loader with GPU→CPU fallback"),
        ("☾ Fold Time", transcribe_file,     "Folds audio→text, base case = existing file"),
        ("☾ Fold Time", batch_transcribe,    "Folds directory→transcripts via AudioIngest"),
        ("☾ Fold Time", transcribe_segment,  "Folds a time slice→text at 16kHz"),
    ]

    for glyph, fn, desc in apis:
        sig = inspect.signature(fn)
        print(f"  {glyph:<12} {fn.__name__}{sig}")
        print(f"               {desc}")
        print()

    # ── Show data structures ──
    section("Data Structures")

    for cls in [TranscriptSegment, Transcript]:
        fields = [(f.name, f.type) for f in cls.__dataclass_fields__.values()]
        field_str = ", ".join(f"{n}: {t}" for n, t in fields)
        print(f"  {cls.__name__}({field_str})")

    # ── Show SCP compliance ──
    section("SCP Compliance — Weaver Verification: PASS")

    checks = [
        ("Interface conformance", "All 4 methods match required signatures"),
        ("Dependency isolation",  "Only AudioIngest + VoiceDetector imported"),
        ("Forbidden imports",     "SearchEngine, Analyzer, LLMProvider — excluded"),
        ("Constraint adherence",  "skip_existing, [PROGRESS] markers, GPU fallback"),
        ("Glyph contracts",       "◬ singleton, ☾ base cases, no side-effect leaks"),
    ]

    for check, detail in checks:
        print(f"  ✔ {check:<25} {detail}")

    # ── Show source highlights ──
    section("Source Highlights")

    # Show the GPU fallback logic
    src = inspect.getsource(load_model)
    # Find the fallback section
    for i, line in enumerate(src.split('\n')):
        if 'fallback' in line.lower() or 'cpu' in line.lower():
            start = max(0, i - 1)
            end = min(len(src.split('\n')), i + 3)
            snippet = '\n'.join(src.split('\n')[start:end])
            print("  GPU→CPU fallback (from load_model):")
            for s_line in snippet.split('\n'):
                print(f"    {s_line}")
            print()
            break

    # ── Usage example ──
    section("Usage")

    print("  from transcriber import load_model, transcribe_file")
    print()
    print("  model = load_model('base.en', 'cuda', 'float16')")
    print("  result = transcribe_file('meeting.wav', 'base.en', beam_size=5)")
    print("  print(result.full_text)")

    # ── How to regenerate ──
    section("Regenerate This Module")

    print("  python examples/turboscribe_example.py Transcriber --gemini")
    print("  python examples/turboscribe_example.py Transcriber --gemini --model gemini-2.5-flash")
    print()


if __name__ == "__main__":
    main()
